{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef7dba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar datos\n",
    "data = load_iris()\n",
    "X, y = data.data[:, :2], data.target  # Tomamos solo dos características para poder graficar en 2D\n",
    "\n",
    "# Dividir datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Entrenar modelo KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predicción\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluar modelo\n",
    "print(\"Precisión:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Puntuación F1:\", f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "# Crear malla para regiones de decisión\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
    "                     np.arange(y_min, y_max, 0.1))\n",
    "\n",
    "# Predecir sobre la malla\n",
    "Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Gráfico de las regiones de decisión\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap='viridis')\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, edgecolor='k', cmap='viridis')\n",
    "plt.title(\"Región de Decisión - KNN Clasificador\")\n",
    "plt.xlabel(data.feature_names[0])\n",
    "plt.ylabel(data.feature_names[1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183754ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar datos\n",
    "data = fetch_california_housing()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Dividir datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Entrenar modelo de Bosques Aleatorios\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predicción\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluar modelo\n",
    "print(\"Error Cuadrático Medio:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"Coeficiente de Determinación R²:\", r2_score(y_test, y_pred))\n",
    "\n",
    "# Gráfico de Predicción vs Real\n",
    "plt.scatter(y_test, y_pred, alpha=0.5, color='b')\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=3)\n",
    "plt.xlabel(\"Valores Reales\")\n",
    "plt.ylabel(\"Predicciones\")\n",
    "plt.title(\"Predicciones vs Valores Reales - Regresión con Bosques Aleatorios\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4899e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.datasets import make_blobs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Crear datos sintéticos con anomalías\n",
    "X, _ = make_blobs(n_samples=300, centers=1, cluster_std=0.5, random_state=42)\n",
    "X = np.vstack([X, np.random.uniform(low=-6, high=6, size=(20, 2))])  # Añadir anomalías\n",
    "\n",
    "# Modelo Isolation Forest\n",
    "iso_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "y_pred = iso_forest.fit_predict(X)\n",
    "\n",
    "# Visualización de anomalías\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_pred, cmap='coolwarm', edgecolor='k')\n",
    "plt.title(\"Detección de Anomalías con Isolation Forest\")\n",
    "plt.xlabel(\"Eje X\")\n",
    "plt.ylabel(\"Eje Y\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0080b349",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar datos\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "# Reducir dimensionalidad a 2 componentes principales\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Visualización\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis', edgecolor='k')\n",
    "plt.colorbar(scatter)\n",
    "plt.title(\"Reducción de Dimensionalidad con PCA\")\n",
    "plt.xlabel(\"Componente Principal 1\")\n",
    "plt.ylabel(\"Componente Principal 2\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
